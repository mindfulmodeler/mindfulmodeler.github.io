---
published: false

layout: post
title: L-Moments in Environmental Data
date: 2020-01-26
description: Basic introduction to L-Moments and how they can be applied to estimating probability distributions for environmental datasets. 
img:  
fig-caption:
tags: []
categories: [Tutorial]
---

L-moments are used to summarize the shape of a probability distribution and identyf appropriate parameters for them. The name "L-moments" relates to their use in linear combinations 
1. TOC
{:toc}
{:.toc-styling}

## Advantages of L-Moments over comparable techniques
The use of L-Moments is thought to perform better than other methods for identifying the shape of probability distribution and approximating its parameters. This is especially the case for water resource problems where the number of environmental samples taken is pretty small. Compared to conventional moments, L-moments can help the analyst study more probability distributions. For example, this method works well to estimate environmental data in developing countries, which typically have smaller sample sizes. Other advantages of L-moments is that they are not as sensitive to distortion from outliers and that they are less biased than comparable methods.

# Equations
**Measure of Location (L1)**
  L1 = mean

**Ratio Measure of Scale (L-Cv)**
  t2 = L2/L1
  L-Cv is an indicator of variability. It is dimensionless and lies between 0 and 1. When the magnitude of L-Cv is close to 0, it means that there is very little variation in the processes. This means that the process is probably tightly controlled, such as production for advanced missile defense products or space gear.

**Ratio Measure of L-Skewness (t3)**
  t3 = L3/L2
  Looking at skewness gives the analyst an idea of the relative shape of your data. Unlike perfectly bell-shaped Gaussian data, the curve of skewed data will lean heavily to one side or the other (depending on weather it is positively or negatively skewed).

**Ratio Measure of L-Kurtosis (t4)**
  t4 = L4/L2
  Kurtosis is an indicator for how strongly tailed the data are. 

# Method of Moments
- use this for determining the parameters of the probability distribution for the flood frequency analysis
- the technique involves trying to match the moments from the sample to moments of common distributions (those commonly seen in flood frequency, for example)
- caution: sometimes it can be hard to sift through the information generated by the third, fourth, or higher moments. That's when a technique such as <smoothing> can be useful
- looking at the L-moment ratio diagram can be a useful component to helping choose a statistical distribution that roughly represents the area under study


{% highlight ruby %}
pip install lmoments
                    
{% endhighlight %}


{% highlight ruby %}
## ROLLING WINDOW FUNCTION
def rolling_window(A, W, win_shape=(3,3)):
    """
    This function creates a rolling window of dimensions 'winshape' to move over an input array (A). 
    A second array (W) of the same size as (A) is used to calculate the weights.
    
        A = The input array
        W = the weight array e.g.e elvation or max annual precip (A nd W should have the same dimensions)
        win_shape = the shape of the rolling window. Note that the win_shape should not be even-numbered ebcause the 
        calculattion uses the center cell of each moving window to determine the distance (i.e. absolute difference)
        to the other cells in the window.
    """
    for i in win_shape:
        assert (i % 2 ==1)  "window dimensions must be odd-numbered (e.g. (3,3))"
        
    a_list = []
    for i in range(A.shape[0]):
        for j in range(A.shape[1]):
            min_row = i-int(floor(win_shape[0]/2)
            max_row = i+int(floor(win_shape[0]/2)
            min_col = j-int(floor(win_shape[0]/2)
            max_col = j+int(floor(win_shape[0]/2)
            
            #Resize edge windows
            if min_row < 0:
                min_row = 0
            if min_col < 0:
                min_col = 0
            if max_row > A.shape[0]:
                max_row = A.shape[0]
            if max_col > A.shape[1]:
                max_col = A.shape[1]
            
            #Create window(s)
            sub_A = A[min_row:max_row+1, min_col:max_col+1]
            sub_W = A[min_row:max_row+1, min_col:max_col+1] #same size window
                            
            #Get abs difference of center cell to surrounding cells
            diff = abs(sub_W - A[i,j])
                            
            #Get max distance in subarray
            max_sub = np.max(diff)
                            
            #Normalize subarray
            weights = (1-diff/max_sub)
            weights = weights/(sum(weights))
                            
            out = (sub_A*weights)
            a_list.append(np.sum(out))
                            
        f = np.array(a_list).reshape(A.shape[0], A.shape[1])
        return f
                            
                    
{% endhighlight %}


# Conclusion
From this point, goodness-of-fit tests can help to check that the chosen probability distribution was indeed a suitable fit.
- used to calculate sample statistics for individual data sites
- used here for identifying an appropriate probability distribution
- used for finding the suitable parameters for the chosen probability distribution